{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d064af66-1e8b-44c5-a989-625af6a1ba0a",
   "metadata": {},
   "source": [
    "# Computer Vision Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89535d81-38a8-423d-90ef-3f9484c6a8b7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837c51f-47ee-495b-ac92-bd1ace506bce",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c87775-2848-4f01-8279-b6c5ec9c3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python decord matplotlib numpy plotly\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f77f84c-b7b2-4ae4-b466-8c164b845e05",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924decba-ed87-4c85-b1f1-364ec07b1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from decord import VideoReader, cpu\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72e6a2-d155-46fb-9a06-025fd5463364",
   "metadata": {},
   "source": [
    "## Frame Extractions and Pair Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a5006-fd63-47e5-81ec-97403b991a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_with_decord(video_path, frames_dir, every=1, overwrite=False):\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    vr = VideoReader(video_path, ctx=cpu(0))\n",
    "    total_frames = len(vr)\n",
    "    saved = 0\n",
    "    extracted_frame_indices = []  # Keep track of which frames we actually extracted\n",
    "\n",
    "    for idx in range(0, total_frames, every):\n",
    "        frame = vr[idx].asnumpy()\n",
    "        frame_filename = os.path.join(frames_dir, f\"frame_{idx:04d}.jpg\")\n",
    "\n",
    "        if not os.path.exists(frame_filename) or overwrite:\n",
    "            cv2.imwrite(frame_filename, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "            saved += 1\n",
    "            extracted_frame_indices.append(idx)\n",
    "\n",
    "    print(f\"{saved} frames saved to {frames_dir}\")\n",
    "    print(f\"Extracted frame indices: {extracted_frame_indices[:10]}...\")  # Show first 10\n",
    "    return saved, extracted_frame_indices\n",
    "\n",
    "video_path = \"Vid6.mp4\"         # path to input video\n",
    "frames_output = \"extracted_frames\"  # folder to save frames\n",
    "\n",
    "saved_count, EXTRACTED_FRAME_INDICES = extract_frames_with_decord(video_path, frames_output, every=5)\n",
    "\n",
    "def generate_evaluation_pairs(extracted_indices, num_pairs=8):\n",
    "    pairs = []\n",
    "    total_frames = len(extracted_indices)\n",
    "    \n",
    "    # Half small gaps, half large gaps\n",
    "    num_small = num_pairs // 2\n",
    "    num_large = num_pairs - num_small\n",
    "    \n",
    "    # Small gaps (2 frames apart)\n",
    "    step = max(1, total_frames // (num_small + 2))\n",
    "    for i in range(0, total_frames - 2, step):\n",
    "        if len(pairs) >= num_small:\n",
    "            break\n",
    "        idx1 = extracted_indices[i]\n",
    "        idx2 = extracted_indices[i + 2]\n",
    "        pairs.append((idx1, idx2))\n",
    "    \n",
    "    # Large gaps (spread across the video)\n",
    "    for i in range(num_large):\n",
    "        start_pos = (i * total_frames) // num_large\n",
    "        end_pos = min(start_pos + total_frames // 4, total_frames - 1)  # Jump by ~25% of video\n",
    "        if start_pos < end_pos:\n",
    "            idx1 = extracted_indices[start_pos]\n",
    "            idx2 = extracted_indices[end_pos]\n",
    "            pairs.append((idx1, idx2))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "frame_pairs = generate_evaluation_pairs(EXTRACTED_FRAME_INDICES, num_pairs=8)\n",
    "print(f\"Selected {len(frame_pairs)} frame pairs for qualitative assessment:\")\n",
    "for i, (idx1, idx2) in enumerate(frame_pairs):\n",
    "    gap = abs(idx2 - idx1)\n",
    "    print(f\"  Pair {i+1}: ({idx1}, {idx2}) - gap: {gap} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054aa803-0a1c-47e3-9622-544cccbfa0d3",
   "metadata": {},
   "source": [
    "## Feature Detection and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17986974-fb08-4c72-95f2-6b679536f8b4",
   "metadata": {},
   "source": [
    "### Loading algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696cdb7-eb5b-4433-ba37-7a049ea98c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kps_descriptors(detector, label=\"\"):\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "\n",
    "    frame_files = sorted([f for f in os.listdir(frames_output) if f.endswith(\".jpg\")])\n",
    "\n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    for filename in frame_files:\n",
    "        frame_path = os.path.join(frames_output, filename)\n",
    "        image = cv2.imread(frame_path, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            continue\n",
    "        kps, desc = detector.detectAndCompute(image, None)\n",
    "        keypoints.append(kps)\n",
    "        descriptors.append(desc)\n",
    "\n",
    "    end_time = time.time()  # End timing\n",
    "    elapsed = end_time - start_time\n",
    "    print(f\"{label} took {elapsed:.2f} seconds to detect and describe {len(keypoints)} frames.\")\n",
    "\n",
    "    return keypoints, descriptors\n",
    "\n",
    "orb = cv2.ORB_create(nfeatures=2000)\n",
    "sift = cv2.SIFT_create()\n",
    "akaze = cv2.AKAZE_create()\n",
    "\n",
    "orb_kps, orb_desc = kps_descriptors(cv2.ORB_create(nfeatures=2000), label=\"ORB\")\n",
    "sift_kps, sift_desc = kps_descriptors(cv2.SIFT_create(), label=\"SIFT\")\n",
    "akaze_kps, akaze_desc = kps_descriptors(cv2.AKAZE_create(), label=\"AKAZE\")\n",
    "\n",
    "kps_dict = {\n",
    "    \"ORB\": orb_kps,\n",
    "    \"SIFT\": sift_kps,\n",
    "    \"AKAZE\": akaze_kps\n",
    "}\n",
    "desc_dict = {\n",
    "    \"ORB\": orb_desc,\n",
    "    \"SIFT\": sift_desc,\n",
    "    \"AKAZE\": akaze_desc\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5f7dc-8c63-4fd5-b4fb-03237e621681",
   "metadata": {},
   "source": [
    "### Number of detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac360c3-62bb-4231-baa4-46b1cfcbbf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(detector_data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for label, keypoints in detector_data:\n",
    "        frame_numbers = list(range(len(keypoints)))\n",
    "        keypoint_counts = [len(kps) for kps in keypoints]\n",
    "        plt.plot(frame_numbers, keypoint_counts, label=label, marker='o')\n",
    "\n",
    "    plt.xlabel(\"Frame Number\")\n",
    "    plt.ylabel(\"Number of Keypoints Detected\")\n",
    "    plt.title(\"Keypoints per Frame by Detector\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "counts(list(kps_dict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4ce78-63eb-4774-a18f-76d7664a6094",
   "metadata": {},
   "source": [
    "### Feature Matching and Matching Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52baa5-37ab-482d-86a3-176658295656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_and_draw_combined(img1, kps1_dict, desc1_dict, img2, kps2_dict, desc2_dict, methods=[\"ORB\", \"SIFT\", \"AKAZE\"]):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 6))\n",
    "    \n",
    "    for idx, method in enumerate(methods):\n",
    "        kps1 = kps1_dict[method]\n",
    "        desc1 = desc1_dict[method]\n",
    "        kps2 = kps2_dict[method]\n",
    "        desc2 = desc2_dict[method]\n",
    "        \n",
    "        if method == \"ORB\" or method == \"AKAZE\":\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            matches = bf.match(desc1, desc2)\n",
    "        elif method == \"SIFT\":\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "            raw_matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "            matches = [m for m, n in raw_matches if m.distance < 0.75 * n.distance]\n",
    "        \n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        \n",
    "        matched_img = cv2.drawMatches(img1, kps1, img2, kps2, matches[:100], None, flags=2)\n",
    "        \n",
    "        axes[idx].imshow(cv2.cvtColor(matched_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f\"{method} - {len(matches)} total matches\")\n",
    "        axes[idx].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {method: matches for method, matches in zip(methods, [matches])}\n",
    "\n",
    "def load_frame(idx):\n",
    "    path = os.path.join(frames_output, f\"frame_{idx:04d}.jpg\")\n",
    "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "def compare_matching_performance(frame_pairs, kps_dict, desc_dict, methods=[\"ORB\", \"SIFT\", \"AKAZE\"]):\n",
    "    \n",
    "    for idx1, idx2 in frame_pairs:\n",
    "        img1 = load_frame(idx1)\n",
    "        img2 = load_frame(idx2)\n",
    "\n",
    "        if img1 is None or img2 is None:\n",
    "            print(f\"Skipped pair ({idx1}, {idx2}) due to missing frame.\")\n",
    "            continue\n",
    "\n",
    "        # Convert frame indices to data structure indices\n",
    "        try:\n",
    "            i1 = EXTRACTED_FRAME_INDICES.index(idx1)\n",
    "            i2 = EXTRACTED_FRAME_INDICES.index(idx2)\n",
    "        except ValueError:\n",
    "            print(f\"Frame indices {idx1} or {idx2} not found in extracted frames.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nMatching frames {idx1} and {idx2}:\")\n",
    "\n",
    "        # Create dictionaries for this frame pair\n",
    "        kps1_dict = {method: kps_dict[method][i1] for method in methods}\n",
    "        desc1_dict = {method: desc_dict[method][i1] for method in methods}\n",
    "        kps2_dict = {method: kps_dict[method][i2] for method in methods}\n",
    "        desc2_dict = {method: desc_dict[method][i2] for method in methods}\n",
    "        \n",
    "        match_and_draw_combined(img1, kps1_dict, desc1_dict, img2, kps2_dict, desc2_dict, methods)\n",
    "        \n",
    "compare_matching_performance(frame_pairs, kps_dict, desc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a7b45-96ee-4fdf-8264-17824fe95ebe",
   "metadata": {},
   "source": [
    "## Outlier Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05737331-fa13-49d8-9719-f1995bbcf23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ransac_combined(img1, img2, kps1_dict, kps2_dict, matches_dict, methods=[\"ORB\", \"SIFT\", \"AKAZE\"]):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 6))\n",
    "    inliers_dict = {}\n",
    "    \n",
    "    for idx, method in enumerate(methods):\n",
    "        matches = matches_dict[method]\n",
    "        kps1 = kps1_dict[method]\n",
    "        kps2 = kps2_dict[method]\n",
    "        \n",
    "        if len(matches) < 4:\n",
    "            axes[idx].text(0.5, 0.5, f\"Not enough matches\\nfor RANSAC ({len(matches)} matches)\", \n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            axes[idx].set_title(f\"{method} - RANSAC Failed\")\n",
    "            axes[idx].axis(\"off\")\n",
    "            inliers_dict[method] = []\n",
    "            continue\n",
    "\n",
    "        pts1 = np.float32([kps1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        pts2 = np.float32([kps2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "        if mask is None:\n",
    "            axes[idx].text(0.5, 0.5, \"RANSAC failed to\\ncompute homography\", \n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            axes[idx].set_title(f\"{method} - RANSAC Failed\")\n",
    "            axes[idx].axis(\"off\")\n",
    "            inliers_dict[method] = []\n",
    "            continue\n",
    "\n",
    "        inliers = [m for i, m in enumerate(matches) if mask[i]]\n",
    "        inliers_dict[method] = inliers\n",
    "\n",
    "        ransac_img = cv2.drawMatches(img1, kps1, img2, kps2, inliers[:50], None, flags=2)\n",
    "        \n",
    "        axes[idx].imshow(cv2.cvtColor(ransac_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f\"{method} - {len(inliers)} inliers (After RANSAC)\")\n",
    "        axes[idx].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return inliers_dict\n",
    "\n",
    "def compare_matching_performance_ransac(frame_pairs, kps_dict, desc_dict, methods=[\"ORB\", \"SIFT\", \"AKAZE\"]):\n",
    "    \n",
    "    for idx1, idx2 in frame_pairs:\n",
    "        img1 = load_frame(idx1)\n",
    "        img2 = load_frame(idx2)\n",
    "\n",
    "        if img1 is None or img2 is None:\n",
    "            print(f\"Skipped pair ({idx1}, {idx2}) due to missing frame.\")\n",
    "            continue\n",
    "\n",
    "        # Convert frame indices to data structure indices\n",
    "        try:\n",
    "            i1 = EXTRACTED_FRAME_INDICES.index(idx1)\n",
    "            i2 = EXTRACTED_FRAME_INDICES.index(idx2)\n",
    "        except ValueError:\n",
    "            print(f\"Frame indices {idx1} or {idx2} not found in extracted frames.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nMatching frames {idx1} and {idx2}:\")\n",
    "\n",
    "        # Create dictionaries for this frame pair\n",
    "        kps1_dict = {method: kps_dict[method][i1] for method in methods}\n",
    "        desc1_dict = {method: desc_dict[method][i1] for method in methods}\n",
    "        kps2_dict = {method: kps_dict[method][i2] for method in methods}\n",
    "        desc2_dict = {method: desc_dict[method][i2] for method in methods}\n",
    "        \n",
    "        # Get matches for all methods\n",
    "        matches_dict = {}\n",
    "        for method in methods:\n",
    "            if method == \"ORB\" or method == \"AKAZE\":\n",
    "                bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "                matches = bf.match(desc1_dict[method], desc2_dict[method])\n",
    "            elif method == \"SIFT\":\n",
    "                bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "                raw_matches = bf.knnMatch(desc1_dict[method], desc2_dict[method], k=2)\n",
    "                matches = [m for m, n in raw_matches if m.distance < 0.75 * n.distance]\n",
    "            matches_dict[method] = sorted(matches, key=lambda x: x.distance)\n",
    "        \n",
    "        # Show initial matches\n",
    "        match_and_draw_combined(img1, kps1_dict, desc1_dict, img2, kps2_dict, desc2_dict, methods)\n",
    "        \n",
    "        # Show RANSAC results\n",
    "        run_ransac_combined(img1, img2, kps1_dict, kps2_dict, matches_dict, methods)\n",
    "\n",
    "compare_matching_performance_ransac(frame_pairs, kps_dict, desc_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d799755",
   "metadata": {},
   "source": [
    "## Fundamental Matrix Estimation and 3D Reconstruction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd305eb-c797-44d0-acbd-458ebfeaf0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fundamental_matrix(pts1, pts2):\n",
    "    \"\"\"Estimate fundamental matrix using RANSAC for uncalibrated cameras\"\"\"\n",
    "    if len(pts1) < 8:\n",
    "        print(f\"Not enough points for fundamental matrix estimation ({len(pts1)} points).\")\n",
    "        return None, None\n",
    "    \n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, 3.0, 0.99)\n",
    "    \n",
    "    if F is None:\n",
    "        print(\"Failed to estimate fundamental matrix.\")\n",
    "        return None, None\n",
    "    \n",
    "    inlier_pts1 = pts1[mask.ravel() == 1]\n",
    "    inlier_pts2 = pts2[mask.ravel() == 1]\n",
    "    \n",
    "    return F, (inlier_pts1, inlier_pts2)\n",
    "\n",
    "def compute_camera_matrices_from_fundamental(F, pts1, pts2, img_shape):\n",
    "    \"\"\"\n",
    "    Compute camera projection matrices from fundamental matrix for uncalibrated cameras.\n",
    "    Uses canonical camera matrices approach.\n",
    "    \"\"\"\n",
    "    h, w = img_shape[:2]\n",
    "    \n",
    "    # For uncalibrated cameras, we use canonical camera matrices\n",
    "    # First camera at origin\n",
    "    P1 = np.array([[1, 0, 0, 0],\n",
    "                   [0, 1, 0, 0],\n",
    "                   [0, 0, 1, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Compute epipoles from fundamental matrix\n",
    "    # e2 is the left null vector of F (Fe2 = 0)\n",
    "    U, S, Vt = np.linalg.svd(F)\n",
    "    e2 = Vt[-1, :]  # Last row of Vt\n",
    "    e2 = e2 / e2[2] if e2[2] != 0 else e2  # Normalize\n",
    "    \n",
    "    # Create skew-symmetric matrix from e2\n",
    "    e2_skew = np.array([[0, -e2[2], e2[1]],\n",
    "                        [e2[2], 0, -e2[0]],\n",
    "                        [-e2[1], e2[0], 0]])\n",
    "    \n",
    "    # Second camera matrix: P2 = [e2_skew * F | e2]\n",
    "    P2 = np.hstack([e2_skew @ F, e2.reshape(-1, 1)])\n",
    "    \n",
    "    return P1, P2\n",
    "\n",
    "def triangulate_points_uncalibrated(F, pts1, pts2, img_shape):\n",
    "    \"\"\"\n",
    "    Triangulate 3D points using fundamental matrix for uncalibrated cameras\n",
    "    \"\"\"\n",
    "    # Get camera projection matrices from fundamental matrix\n",
    "    P1, P2 = compute_camera_matrices_from_fundamental(F, pts1, pts2, img_shape)\n",
    "    \n",
    "    # Triangulate points using the projection matrices\n",
    "    points_4d = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "    \n",
    "    # Convert from homogeneous to 3D coordinates\n",
    "    points_3d = points_4d[:3] / points_4d[3]\n",
    "    \n",
    "    # Filter out points behind cameras (negative Z in first camera frame)\n",
    "    valid_mask = points_4d[3] != 0  # Valid homogeneous coordinates\n",
    "    points_3d_filtered = points_3d.T[valid_mask.flatten()]\n",
    "    \n",
    "    return points_3d_filtered, P1, P2\n",
    "\n",
    "def process_frame_pair_3d(frame_idx1, frame_idx2, method=\"SIFT\"):\n",
    "    \"\"\"Process a pair of frames and return 3D points using fundamental matrix\"\"\"\n",
    "    \n",
    "    # Load frames\n",
    "    img1 = load_frame(frame_idx1)\n",
    "    img2 = load_frame(frame_idx2)\n",
    "    \n",
    "    if img1 is None or img2 is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Convert frame indices to data structure indices using extracted frame indices\n",
    "    try:\n",
    "        i1 = EXTRACTED_FRAME_INDICES.index(frame_idx1)\n",
    "        i2 = EXTRACTED_FRAME_INDICES.index(frame_idx2)\n",
    "    except ValueError:\n",
    "        print(f\"Frame indices {frame_idx1} or {frame_idx2} not found in extracted frames.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Get keypoints and descriptors\n",
    "    kps1 = kps_dict[method][i1]\n",
    "    desc1 = desc_dict[method][i1]\n",
    "    kps2 = kps_dict[method][i2]\n",
    "    desc2 = desc_dict[method][i2]\n",
    "    \n",
    "    if desc1 is None or desc2 is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Match features\n",
    "    if method == \"ORB\" or method == \"AKAZE\":\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(desc1, desc2)\n",
    "    elif method == \"SIFT\":\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "        raw_matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "        matches = [m for m, n in raw_matches if m.distance < 0.75 * n.distance]\n",
    "    \n",
    "    if len(matches) < 10:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract corresponding points\n",
    "    pts1 = np.float32([kps1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([kps2[m.trainIdx].pt for m in matches])\n",
    "    \n",
    "    # Estimate fundamental matrix (not essential matrix for uncalibrated case)\n",
    "    F, inliers = estimate_fundamental_matrix(pts1, pts2)\n",
    "    \n",
    "    if F is None or inliers is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    inlier_pts1, inlier_pts2 = inliers\n",
    "    \n",
    "    # Triangulate 3D points using fundamental matrix\n",
    "    points_3d, P1, P2 = triangulate_points_uncalibrated(F, inlier_pts1, inlier_pts2, img1.shape)\n",
    "    \n",
    "    # Filter out extreme outliers based on distance from origin\n",
    "    if len(points_3d) > 0:\n",
    "        distances = np.linalg.norm(points_3d, axis=1)\n",
    "        # Remove points that are too far (likely reconstruction errors)\n",
    "        valid_mask = distances < np.percentile(distances, 95)  # Keep 95% of closest points\n",
    "        points_3d_filtered = points_3d[valid_mask]\n",
    "    else:\n",
    "        points_3d_filtered = points_3d\n",
    "    \n",
    "    return points_3d_filtered, F, (P1, P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7651f",
   "metadata": {},
   "source": [
    "## 3D Reconstruction for Multiple Frame Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_3d_scene(methods=[\"SIFT\", \"ORB\", \"AKAZE\"], max_pairs=5):\n",
    "    \"\"\"Reconstruct 3D scene from multiple frame pairs\"\"\"\n",
    "    \n",
    "    # Generate reconstruction pairs from actual extracted frames\n",
    "    # Use every 4th extracted frame to ensure good baseline while maintaining overlap\n",
    "    reconstruction_indices = EXTRACTED_FRAME_INDICES[::4]  # Take every 4th extracted frame\n",
    "    reconstruction_pairs = []\n",
    "    \n",
    "    for i in range(len(reconstruction_indices) - 1):\n",
    "        if len(reconstruction_pairs) >= max_pairs:\n",
    "            break\n",
    "        frame1 = reconstruction_indices[i]\n",
    "        frame2 = reconstruction_indices[i + 1]\n",
    "        reconstruction_pairs.append((frame1, frame2))\n",
    "    \n",
    "    print(f\"Using reconstruction pairs: {reconstruction_pairs}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\nProcessing with {method}...\")\n",
    "        method_results = []\n",
    "        \n",
    "        for frame1, frame2 in reconstruction_pairs:\n",
    "            print(f\"  Processing pair ({frame1}, {frame2})\")\n",
    "            \n",
    "            points_3d, F, pose = process_frame_pair_3d(frame1, frame2, method)\n",
    "            \n",
    "            if points_3d is not None and len(points_3d) > 0:\n",
    "                method_results.append({\n",
    "                    'pair': (frame1, frame2),\n",
    "                    'points_3d': points_3d,\n",
    "                    'fundamental_matrix': F,\n",
    "                    'pose': pose,\n",
    "                    'num_points': len(points_3d)\n",
    "                })\n",
    "                print(f\"    Reconstructed {len(points_3d)} 3D points\")\n",
    "            else:\n",
    "                print(f\"    Failed to reconstruct pair ({frame1}, {frame2})\")\n",
    "        \n",
    "        results[method] = method_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run 3D reconstruction\n",
    "reconstruction_results = reconstruct_3d_scene()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== Reconstruction Summary ===\")\n",
    "for method, results in reconstruction_results.items():\n",
    "    if results:\n",
    "        total_points = sum([r['num_points'] for r in results])\n",
    "        successful_pairs = len(results)\n",
    "        print(f\"{method}: {successful_pairs} successful pairs, {total_points} total 3D points\")\n",
    "    else:\n",
    "        print(f\"{method}: No successful reconstructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a6bc6",
   "metadata": {},
   "source": [
    "## 3D Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0388971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_interactive_3d_plot(reconstruction_results, max_points_per_method=500):\n",
    "    \"\"\"Create interactive 3D visualisation with Plotly\"\"\"\n",
    "    \n",
    "    methods_with_data = [(method, results) for method, results in reconstruction_results.items() if results]\n",
    "    \n",
    "    if not methods_with_data:\n",
    "        print(\"No reconstruction data available for visualisation.\")\n",
    "        return\n",
    "    \n",
    "    n_methods = len(methods_with_data)\n",
    "    \n",
    "    # Create subplots\n",
    "    subplot_titles = [method for method, _ in methods_with_data]\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=n_methods,\n",
    "        specs=[[{'type': 'scatter3d'} for _ in range(n_methods)]],\n",
    "        subplot_titles=subplot_titles\n",
    "    )\n",
    "    \n",
    "    color_palette = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "    \n",
    "    for idx, (method, results) in enumerate(methods_with_data):\n",
    "        all_points = []\n",
    "        colors = []\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            points = result['points_3d']\n",
    "            \n",
    "            # Subsample points\n",
    "            if len(points) > max_points_per_method // len(results):\n",
    "                indices = np.random.choice(len(points), max_points_per_method // len(results), replace=False)\n",
    "                points = points[indices]\n",
    "            \n",
    "            all_points.extend(points)\n",
    "            colors.extend([color_palette[i % len(color_palette)]] * len(points))\n",
    "        \n",
    "        if all_points:\n",
    "            all_points = np.array(all_points)\n",
    "            \n",
    "            # Remove extreme outliers\n",
    "            for dim in range(3):\n",
    "                coord = all_points[:, dim]\n",
    "                q1, q3 = np.percentile(coord, [25, 75])\n",
    "                iqr = q3 - q1\n",
    "                lower_bound = q1 - 1.5 * iqr\n",
    "                upper_bound = q3 + 1.5 * iqr\n",
    "                valid_mask = (coord >= lower_bound) & (coord <= upper_bound)\n",
    "                all_points = all_points[valid_mask]\n",
    "                colors = [colors[i] for i in range(len(colors)) if valid_mask[i]]\n",
    "            \n",
    "            # Add scatter trace\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=all_points[:, 0],\n",
    "                    y=all_points[:, 1], \n",
    "                    z=all_points[:, 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=colors,\n",
    "                        opacity=0.6\n",
    "                    ),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=idx+1\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"3D Reconstruction Results - Click and drag to rotate\",\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    # Update 3D scene properties for each subplot\n",
    "    for i in range(n_methods):\n",
    "        scene_key = f'scene{i+1}' if i > 0 else 'scene'\n",
    "        fig.update_layout(**{\n",
    "            scene_key: dict(\n",
    "                xaxis_title='X',\n",
    "                yaxis_title='Y',\n",
    "                zaxis_title='Z',\n",
    "                aspectmode='cube'\n",
    "            )\n",
    "        })\n",
    "    \n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "# Create the interactive visualization\n",
    "print(\"Creating interactive 3D visualisation...\")\n",
    "print(\"Note: You can rotate by dragging and/or zoom by scrolling into the 3D plots.\")\n",
    "visualization_fig = create_interactive_3d_plot(reconstruction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8b88f",
   "metadata": {},
   "source": [
    "## Analysis and Comparison of Reconstruction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a4644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_reconstruction_quality(reconstruction_results):\n",
    "    \"\"\"Analyze and compare reconstruction quality across methods\"\"\"\n",
    "    \n",
    "    print(\"=== Detailed Reconstruction Analysis ===\\n\")\n",
    "    \n",
    "    method_stats = {}\n",
    "    \n",
    "    for method, results in reconstruction_results.items():\n",
    "        if not results:\n",
    "            print(f\"{method}: No successful reconstructions\")\n",
    "            continue\n",
    "            \n",
    "        point_counts = [r['num_points'] for r in results]\n",
    "        total_points = sum(point_counts)\n",
    "        avg_points = total_points / len(results) if results else 0\n",
    "        successful_pairs = len(results)\n",
    "        \n",
    "        all_points = []\n",
    "        for result in results:\n",
    "            all_points.extend(result['points_3d'])\n",
    "        \n",
    "        if all_points:\n",
    "            all_points = np.array(all_points)\n",
    "            spreads = [np.std(all_points[:, i]) for i in range(3)]\n",
    "            avg_spread = np.mean(spreads)\n",
    "        else:\n",
    "            avg_spread = 0\n",
    "        \n",
    "        method_stats[method] = {\n",
    "            'successful_pairs': successful_pairs,\n",
    "            'total_points': total_points,\n",
    "            'avg_points_per_pair': avg_points,\n",
    "            'avg_spread': avg_spread\n",
    "        }\n",
    "        \n",
    "        print(f\"{method}:\")\n",
    "        print(f\"  Successful pairs: {successful_pairs}\")\n",
    "        print(f\"  Total 3D points: {total_points}\")\n",
    "        print(f\"  Average points per pair: {avg_points:.1f}\")\n",
    "        print(f\"  Average coordinate spread: {avg_spread:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    # Create comparison plot\n",
    "    if method_stats:\n",
    "        methods = list(method_stats.keys())\n",
    "        total_points = [method_stats[m]['total_points'] for m in methods]\n",
    "        successful_pairs = [method_stats[m]['successful_pairs'] for m in methods]\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=('Total Points by Method', 'Successful Reconstructions by Method')\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x=methods, y=total_points, name='Total Points'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x=methods, y=successful_pairs, name='Successful Pairs'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=\"Reconstruction Method Comparison\",\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    return method_stats\n",
    "\n",
    "# Run analysis\n",
    "analysis_results = analyze_reconstruction_quality(reconstruction_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc31507",
   "metadata": {},
   "source": [
    "## Reprojection Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reprojection_error(points_3d, pts1, pts2, P1, P2):\n",
    "    \"\"\"Calculate basic reprojection error for 3D points\"\"\"\n",
    "    if len(points_3d) == 0:\n",
    "        return float('inf'), float('inf')\n",
    "    \n",
    "    # Convert 3D points to homogeneous coordinates\n",
    "    points_3d_homo = np.hstack([points_3d, np.ones((len(points_3d), 1))])\n",
    "    \n",
    "    # Project 3D points back to both images\n",
    "    proj1 = P1 @ points_3d_homo.T\n",
    "    proj2 = P2 @ points_3d_homo.T\n",
    "    \n",
    "    # Convert from homogeneous to 2D\n",
    "    proj1_2d = (proj1[:2] / proj1[2]).T\n",
    "    proj2_2d = (proj2[:2] / proj2[2]).T\n",
    "    \n",
    "    # Calculate reprojection errors\n",
    "    error1 = np.linalg.norm(pts1[:len(points_3d)] - proj1_2d, axis=1)\n",
    "    error2 = np.linalg.norm(pts2[:len(points_3d)] - proj2_2d, axis=1)\n",
    "    \n",
    "    return np.mean(error1), np.mean(error2)\n",
    "\n",
    "def analyze_reprojection_errors(reconstruction_results):\n",
    "    \"\"\"Basic quantitative analysis using reprojection error\"\"\"\n",
    "    \n",
    "    print(\"\\n=== Reprojection Error Analysis ===\\n\")\n",
    "    \n",
    "    for method, results in reconstruction_results.items():\n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        print(f\"{method}:\")\n",
    "        method_errors = []\n",
    "        \n",
    "        for result in results:\n",
    "            # Get data for this reconstruction\n",
    "            points_3d = result['points_3d']\n",
    "            P1, P2 = result['pose']\n",
    "            pair = result['pair']\n",
    "            \n",
    "            # Load frames and get matching points\n",
    "            frame1, frame2 = pair\n",
    "            img1 = load_frame(frame1)\n",
    "            img2 = load_frame(frame2)\n",
    "            \n",
    "            if img1 is None or img2 is None:\n",
    "                continue\n",
    "                \n",
    "            # Get feature matches for this pair (simplified - using first N points)\n",
    "            try:\n",
    "                i1 = EXTRACTED_FRAME_INDICES.index(frame1)\n",
    "                i2 = EXTRACTED_FRAME_INDICES.index(frame2)\n",
    "                \n",
    "                kps1 = kps_dict[method][i1]\n",
    "                desc1 = desc_dict[method][i1]\n",
    "                kps2 = kps_dict[method][i2]\n",
    "                desc2 = desc_dict[method][i2]\n",
    "                \n",
    "                # Get matches\n",
    "                if method == \"ORB\" or method == \"AKAZE\":\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "                    matches = bf.match(desc1, desc2)\n",
    "                elif method == \"SIFT\":\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "                    raw_matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "                    matches = [m for m, n in raw_matches if m.distance < 0.75 * n.distance]\n",
    "                \n",
    "                # Get point correspondences\n",
    "                pts1 = np.float32([kps1[m.queryIdx].pt for m in matches[:len(points_3d)]])\n",
    "                pts2 = np.float32([kps2[m.trainIdx].pt for m in matches[:len(points_3d)]])\n",
    "                \n",
    "                # Calculate reprojection errors\n",
    "                error1, error2 = calculate_reprojection_error(points_3d, pts1, pts2, P1, P2)\n",
    "                avg_error = (error1 + error2) / 2\n",
    "                method_errors.append(avg_error)\n",
    "                \n",
    "                print(f\"  Pair ({frame1}, {frame2}): {avg_error:.2f} pixels\")\n",
    "                \n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "        \n",
    "        if method_errors:\n",
    "            overall_avg = np.mean(method_errors)\n",
    "            print(f\"  Average reprojection error: {overall_avg:.2f} pixels\")\n",
    "        else:\n",
    "            print(\"  No valid error measurements\")\n",
    "        print()\n",
    "\n",
    "# Run reprojection error analysis\n",
    "analyze_reprojection_errors(reconstruction_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
